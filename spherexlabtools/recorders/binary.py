""" This module implements Recorder sub-classes that write to binary output files.
"""

import os

import numpy as np
import pandas as pd
from astropy.io import fits

import spherexlabtools.log as slt_log
from spherexlabtools.recorders import Recorder


class HDFRecorder(Recorder):
    """ A non-merging recorder that writes the data, procedure parameters, and metadata tables into three separate groups
    of an HDF5 file:

        1. 'data'
        2. 'proc_params'
        3. 'meta'
    """

    _data_group_str = "data"
    _pp_group_str = "proc_params"
    _meta_group_str = "meta"

    def __init__(self, cfg, exp, **kwargs):
        super().__init__(cfg, exp, extension=".h5", merge=False, **kwargs)

    def open_results(self, exists):
        """ Open existing or create a new .h5 file. If the file exists then read the latest RecordGroup and RecordGroupInd
        values from the 'proc_params' group.

        :return: The appropriate RecordGroup and RecordGroupInd values.
        """
        fp = self.results_path.value()
        self.opened_results = pd.HDFStore(fp)
        if exists:
            rec_group, rec_group_ind = self.opened_results[self._pp_group_str].index[-1]
        else:
            rec_group = -1
            rec_group_ind = -1

        return rec_group, rec_group_ind

    def close_results(self):
        """ Close the .h5 results file.
        """
        if self.opened_results is not None:
            self.opened_results.close()
            self.opened_results = None

    def update_results(self):
        """ Append to the HDF groups with the information from the new dataframes.
        """
        self.opened_results.append(self._data_group_str, self.data_df)
        self.opened_results.append(self._pp_group_str, self.pp_df)
        self.opened_results.append(self._meta_group_str, self.meta_df)


class FITSRecorder(Recorder):
    """ This class implements writing to .fits output, generating a new fits file for each individual
    RecordGroup in a measurement. Files always have the record group number appended to the file-name. Thus, in the
    case of the :ref:`SLT Data Output Example <user_guide/data_output/standard:Example>`, there would be two files
    generated for each measurement performed. The first would have '_0' appended, while the second file would have
    '_1' appended. Every fits file generated by this recorder contains two header-data-units (HDUs). The first HDU is
    the *primary* HDU where the data table is written, while the second is a binary table HDU that contains all
    information from the metadata and procedure parameters tables. In more detail, the HDUs are structured as follows:

    **Primary HDU (Data table)**
    The primary HDU data attribute is a cube array of all of the records generated in a single *RecordGroup*.
    The cube is structured with the first dimension being the *RecordGroupInd*, the second dimension being the *RecordRow*,
    and the final dimension being the *column* within the record. Note that for any given fits file (RecordGroup), the
    number of *RecordRows* must remain fixed.

    The header attribute of the primary HDU contains the following entries, some of which are created by default through
    the astropy fits writer:

        - SIMPLE: boolean indicating if the file conforms to the FITS standard
        - BITPIX: data type of the array
        - NAXIS: number of array dimensions (will always be 3)
        - NAXIS1: number of columns in each record.
        - NAXIS2: number of rows in each record (RecordRow).
        - NAXIS3: number of records stored (RecordGroupInd).
        - COL\_#: Only present if the initialization kwarg *label_datacols* is set to True (default False). Here, there
                 will be an entry for every column present in a record where # is replaced with the column number. The
                 contents of each entry is then the string name identifying the column.

    **Extension HDU (Metadata / Procedure Parameters table)**
    The data attribute is a table with the *procedure parameters* and *metadata* tables joined along with the *RecordGroupInd*
    and *RecordRow* information.

    The header is simply the the default header for the BinTableHDU type in astropy. The entries that are of interest
    are the following:

        - NAXIS2: number of records in the table.
        - TFIELDS: number of table columns
        - TTYPE#: string label of column number #.
        - TFORM#: data type of column number #.

    *note: the opened_results attribute is used to hold the primary header data unit.*
    """

    _rg_append_char = '_'

    def __init__(self, cfg, exp, label_datacols=False, **kwargs):
        """ Initialize a FITSRecorder

        :param cfg: Configuration dictionary.
        :param exp: Experiment control package.
        :param label_datacols: Boolean indicating if the primary HDU should contain column labels in the header.
        :param kwargs: Base recorder kwargs.
        """
        super().__init__(cfg, exp, extension=".fits", merge=True, **kwargs)
        self._prev_rec_group = None
        self.label_datacols = label_datacols
        self.meta_pp_cols = []

    def should_open(self, record):
        """ Override the base should_open method to check if a directory for fits files exists, rather than a single
        file.

        :param record:
        :return:
        """
        fp = record.recorder_write_path
        fp_exists = os.path.exists(fp)
        if (not fp_exists) or (self.results_path != fp):
            ret = fp
        else:
            ret = False

        return (ret, fp_exists)

    def open_results(self, exists):
        """ Open existing or create a new .fits output directory. If the directory exists, then get the latest record
        group.

        :param exists:
        :return:
        """
        if not exists:
            os.makedirs(self.results_path, exist_ok=True)

        self.opened_results = None
        fits_files = [f.replace(self.extension, '') for f in os.listdir(self.results_path) if self.extension in f]
        if not exists or len(fits_files) == 0:
            rec_group = -1
            rec_group_ind = -1
        else:
            fits_files.sort()
            rec_group = int(fits_files[-1].split(self._rg_append_char)[-1])
            rec_group_ind = -1

        self._prev_rec_group = rec_group
        return rec_group, rec_group_ind

    def close_results(self):
        self.opened_results.close()

    def update_results(self):

        data_values = self.data_df.values.astype(np.float64)
        data_values = np.array([data_values])

        # - if a new record group, then open a new HDUL and write the data header - #
        if self._prev_rec_group != self.record_group:
            # - update the meta_pp_columns - #
            self.meta_pp_columns = [col for col in self.merged_df.columns if 'proc' in str(col) or 'meta' in str(col)]

            # - create the primary hdu - #
            phdu = fits.PrimaryHDU(data_values)
            if self.label_datacols:
                icol = 0
                for col in self.data_df.columns:
                    col_str = 'COL_%i' % icol
                    phdu.header[col_str] = col
                    icol += 1

            # - create the extension hdu - #
            rgi_col = fits.Column(name='RecordGroupInd', format='K', array=[self.record_group_ind])
            cols = [rgi_col]
            for col in self.meta_pp_columns:
                if 'proc' in col:
                    array = self.pp_df[col]
                elif 'meta' in col:
                    array = self.meta_df[col]
                column = fits.Column(name=col, format='K', array=array)
                cols.append(column)
            ext_hdu = fits.BinTableHDU.from_columns(cols)

            # - create the HDUL - #
            self.opened_results = fits.HDUList([phdu, ext_hdu])

        # - otherwise just append to the existing HDUL - #
        else:
            # - append to the primary HDU - #
            phdu_data = self.opened_results[0].data
            phdu_data = np.concatenate([phdu_data, data_values])
            self.opened_results[0].data = phdu_data

            # - append to the extension HDU - #
            ext_dtype = self.opened_results[1].data.dtype
            ext_list = [self.record_group_ind]
            for col in self.meta_pp_columns:
                if 'proc' in col:
                    array = self.pp_df[col]
                elif 'meta' in col:
                    array = self.meta_df[col]
                ext_list.extend(array)
            ext_append = np.array([tuple(ext_list)], dtype=ext_dtype)
            ext_data = np.concatenate([self.opened_results[1].data, ext_append])
            self.opened_results[1].data = ext_data

        # - write the fits file - #
        path = os.path.join(self.results_path, 'rg%s%04i.fits' % (self._rg_append_char, self.record_group))
        self.opened_results.writeto(path, overwrite=True)

        # - update the previous record group attribute - #
        self._prev_rec_group = self.record_group

